{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day0810_colab_cifar10_best.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OWEN-JUN/keras_/blob/master/day0810_colab_cifar10_best.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwSCzSuozrGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "data_generator = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.08,\n",
        "    height_shift_range=0.08,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "# X_train, _, Y_train, _ = train_test_split(X_train, Y_train, test_size=0.994)\n",
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255\n",
        "\n",
        "X_train = X_train.reshape(X_train.shape[0], 32 ,32, 3)  \n",
        "X_test = X_test.reshape(X_test.shape[0], 32 ,32, 3)\n",
        "\n",
        "\n",
        "Y_train = np_utils.to_categorical(Y_train)      \n",
        "Y_test = np_utils.to_categorical(Y_test)        \n",
        "\n",
        "\n",
        "IMG_CHANNERLS = 3\n",
        "IMG_ROWS = 32\n",
        "IMG_COLS = 32\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(X_train[0])\n",
        "# data_scaling(X_train)\n",
        "# print(X_train[0])\n",
        "# X_train = X_train.reshape(X_train.shape[0], 32 ,32 ,3).astype('float32') / 255\n",
        "# print(X_train[0])\n",
        "\n",
        "def build_network_cnn(keep_prob=0.1, optimizer='adam', conv1 = 20, conv2=30):\n",
        "    \n",
        "    inputs = Input(shape=(32,32,3), name='input')\n",
        "    \n",
        "    x = Conv2D(conv1,(3,3),padding=\"same\",activation=\"relu\", input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNERLS))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(conv1, (3,3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(keep_prob)(x)\n",
        "    \n",
        "    x = Conv2D(conv2,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(conv2, (3,3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(keep_prob)(x)\n",
        "    \n",
        "    \n",
        "#     x = Conv2D(conv3,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = Conv2D(conv3, (3,3), activation='relu')(x)\n",
        "#     x = BatchNormalization()(x)\n",
        "#     x = MaxPooling2D(pool_size=2)(x)\n",
        "#     x = Dropout(keep_prob)(x)\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    prediction = Dense(10, activation='softmax', name='output')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=prediction)\n",
        " \n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',  \n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "#     model.fit_generator(data_generator.flow(X_train, Y_train, batch_size=256),\n",
        "#                         steps_per_epoch=100,     \n",
        "#                         epochs=3,\n",
        "#                         verbose=1)  \n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "def create_hyperparameters():\n",
        "    batches = [10,20,30,40,50]\n",
        "    optimizers = ['rmsprop', 'adam', 'adadelta']\n",
        "    dropout = np.linspace(0.05,0.5, 10)\n",
        "    epochs = [10,50,100,150, 200]\n",
        "    conv1 = [30,40,50,60,70]\n",
        "    conv2 = [30,40,50,60,70]\n",
        "#     conv3 = [30,40,50,60,70]\n",
        "    return {\"model__batch_size\":batches, \"model__optimizer\":optimizers, \"model__keep_prob\":dropout, \"model__epochs\":epochs,\"model__conv1\":conv1,\"model__conv2\":conv2}      # Map 형태로 반환\n",
        "\n",
        "# def data_scaling(x_data):\n",
        "#     x_data = x_data.reshape(x_data.shape[0], 32* 32* 3) \n",
        "#     MinMaxScaler()\n",
        "#     x_data = x_data.reshape(x_data.shape[0], 32, 32, 3)  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRB9gkLLzyB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0ffbbb2d-15a7-45f4-c49a-f239c1c2b939"
      },
      "source": [
        "# score : {'model__optimizer': 'adadelta', 'model__keep_prob': 0.05, 'model__epochs': 200, 'model__conv2': 60, 'model__conv1': 30, 'model__batch_size': 50}\n",
        "early = EarlyStopping(monitor=\"loss\", patience=10, mode=\"auto\")\n",
        "model = build_network_cnn(keep_prob=0.05, optimizer='adadelta', conv1 = 30, conv2=60)\n",
        "model.fit(X_train,Y_train,batch_size=50, epochs=200, callbacks=[early])\n",
        "\n",
        "print(\"acc:\", model.evaluate(X_test,Y_test))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "50000/50000 [==============================] - 11s 216us/step - loss: 1.3421 - acc: 0.5447\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.8711 - acc: 0.6955\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.7305 - acc: 0.7472\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.6389 - acc: 0.7799\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 10s 192us/step - loss: 0.5730 - acc: 0.8013\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.5199 - acc: 0.8179\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.4729 - acc: 0.8353\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.4347 - acc: 0.8482\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.3994 - acc: 0.8606\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 10s 190us/step - loss: 0.3687 - acc: 0.8709\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.3405 - acc: 0.8805\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.3185 - acc: 0.8866\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.2924 - acc: 0.8970\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.2787 - acc: 0.8997\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.2583 - acc: 0.9079\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.2414 - acc: 0.9119\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.2326 - acc: 0.9155\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.2188 - acc: 0.9216\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.2071 - acc: 0.9248\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.1954 - acc: 0.9290\n",
            "Epoch 21/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.1851 - acc: 0.9327\n",
            "Epoch 22/200\n",
            "50000/50000 [==============================] - 10s 193us/step - loss: 0.1804 - acc: 0.9350\n",
            "Epoch 23/200\n",
            "50000/50000 [==============================] - 10s 194us/step - loss: 0.1697 - acc: 0.9382\n",
            "Epoch 24/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.1650 - acc: 0.9396\n",
            "Epoch 25/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.1570 - acc: 0.9428\n",
            "Epoch 26/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.1532 - acc: 0.9440\n",
            "Epoch 27/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.1471 - acc: 0.9460\n",
            "Epoch 28/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.1430 - acc: 0.9484\n",
            "Epoch 29/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.1395 - acc: 0.9494\n",
            "Epoch 30/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.1325 - acc: 0.9514\n",
            "Epoch 31/200\n",
            "50000/50000 [==============================] - 10s 190us/step - loss: 0.1273 - acc: 0.9535\n",
            "Epoch 32/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.1269 - acc: 0.9539\n",
            "Epoch 33/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.1201 - acc: 0.9555\n",
            "Epoch 34/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.1202 - acc: 0.9567\n",
            "Epoch 35/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.1160 - acc: 0.9584\n",
            "Epoch 36/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.1145 - acc: 0.9590\n",
            "Epoch 37/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.1096 - acc: 0.9612\n",
            "Epoch 38/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.1074 - acc: 0.9600\n",
            "Epoch 39/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.1036 - acc: 0.9623\n",
            "Epoch 40/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.1038 - acc: 0.9621\n",
            "Epoch 41/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.1034 - acc: 0.9627\n",
            "Epoch 42/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.1026 - acc: 0.9640\n",
            "Epoch 43/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0975 - acc: 0.9651\n",
            "Epoch 44/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0946 - acc: 0.9664\n",
            "Epoch 45/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0939 - acc: 0.9655\n",
            "Epoch 46/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0925 - acc: 0.9671\n",
            "Epoch 47/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0896 - acc: 0.9666\n",
            "Epoch 48/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0869 - acc: 0.9690\n",
            "Epoch 49/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0886 - acc: 0.9679\n",
            "Epoch 50/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0839 - acc: 0.9699\n",
            "Epoch 51/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0846 - acc: 0.9689\n",
            "Epoch 52/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0829 - acc: 0.9705\n",
            "Epoch 53/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0836 - acc: 0.9696\n",
            "Epoch 54/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.0828 - acc: 0.9700\n",
            "Epoch 55/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0786 - acc: 0.9718\n",
            "Epoch 56/200\n",
            "50000/50000 [==============================] - 10s 193us/step - loss: 0.0782 - acc: 0.9719\n",
            "Epoch 57/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0758 - acc: 0.9726\n",
            "Epoch 58/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0776 - acc: 0.9717\n",
            "Epoch 59/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0767 - acc: 0.9729\n",
            "Epoch 60/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0743 - acc: 0.9728\n",
            "Epoch 61/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0749 - acc: 0.9721\n",
            "Epoch 62/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0701 - acc: 0.9751\n",
            "Epoch 63/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0753 - acc: 0.9731\n",
            "Epoch 64/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0742 - acc: 0.9732\n",
            "Epoch 65/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0698 - acc: 0.9747\n",
            "Epoch 66/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0728 - acc: 0.9734\n",
            "Epoch 67/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0671 - acc: 0.9760\n",
            "Epoch 68/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0622 - acc: 0.9774\n",
            "Epoch 69/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0673 - acc: 0.9753\n",
            "Epoch 70/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0652 - acc: 0.9764\n",
            "Epoch 71/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0663 - acc: 0.9762\n",
            "Epoch 72/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0652 - acc: 0.9774\n",
            "Epoch 73/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0627 - acc: 0.9780\n",
            "Epoch 74/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0640 - acc: 0.9770\n",
            "Epoch 75/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0653 - acc: 0.9771\n",
            "Epoch 76/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0607 - acc: 0.9786\n",
            "Epoch 77/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0623 - acc: 0.9775\n",
            "Epoch 78/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0571 - acc: 0.9796\n",
            "Epoch 79/200\n",
            "50000/50000 [==============================] - 9s 185us/step - loss: 0.0597 - acc: 0.9789\n",
            "Epoch 80/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0567 - acc: 0.9803\n",
            "Epoch 81/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0581 - acc: 0.9794\n",
            "Epoch 82/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0566 - acc: 0.9795\n",
            "Epoch 83/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0557 - acc: 0.9807\n",
            "Epoch 84/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0563 - acc: 0.9793\n",
            "Epoch 85/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0559 - acc: 0.9809\n",
            "Epoch 86/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0569 - acc: 0.9795\n",
            "Epoch 87/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.0566 - acc: 0.9801\n",
            "Epoch 88/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0568 - acc: 0.9805\n",
            "Epoch 89/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.0542 - acc: 0.9803\n",
            "Epoch 90/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.0549 - acc: 0.9808\n",
            "Epoch 91/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0566 - acc: 0.9802\n",
            "Epoch 92/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0537 - acc: 0.9812\n",
            "Epoch 93/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0556 - acc: 0.9806\n",
            "Epoch 94/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0511 - acc: 0.9815\n",
            "Epoch 95/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0516 - acc: 0.9813\n",
            "Epoch 96/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0507 - acc: 0.9822\n",
            "Epoch 97/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0495 - acc: 0.9822\n",
            "Epoch 98/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0499 - acc: 0.9825\n",
            "Epoch 99/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0482 - acc: 0.9830\n",
            "Epoch 100/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0508 - acc: 0.9820\n",
            "Epoch 101/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0490 - acc: 0.9829\n",
            "Epoch 102/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0522 - acc: 0.9813\n",
            "Epoch 103/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0501 - acc: 0.9818\n",
            "Epoch 104/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0478 - acc: 0.9832\n",
            "Epoch 105/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0497 - acc: 0.9823\n",
            "Epoch 106/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0492 - acc: 0.9826\n",
            "Epoch 107/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0488 - acc: 0.9826\n",
            "Epoch 108/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0500 - acc: 0.9828\n",
            "Epoch 109/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0481 - acc: 0.9836\n",
            "Epoch 110/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0452 - acc: 0.9842\n",
            "Epoch 111/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0492 - acc: 0.9825\n",
            "Epoch 112/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0483 - acc: 0.9831\n",
            "Epoch 113/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0460 - acc: 0.9840\n",
            "Epoch 114/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0476 - acc: 0.9832\n",
            "Epoch 115/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0481 - acc: 0.9835\n",
            "Epoch 116/200\n",
            "50000/50000 [==============================] - 9s 190us/step - loss: 0.0448 - acc: 0.9842\n",
            "Epoch 117/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0463 - acc: 0.9839\n",
            "Epoch 118/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0458 - acc: 0.9844\n",
            "Epoch 119/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0439 - acc: 0.9846\n",
            "Epoch 120/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0434 - acc: 0.9844\n",
            "Epoch 121/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0438 - acc: 0.9839\n",
            "Epoch 122/200\n",
            "50000/50000 [==============================] - 10s 190us/step - loss: 0.0449 - acc: 0.9837\n",
            "Epoch 123/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0418 - acc: 0.9852\n",
            "Epoch 124/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0414 - acc: 0.9853\n",
            "Epoch 125/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0425 - acc: 0.9854\n",
            "Epoch 126/200\n",
            "50000/50000 [==============================] - 9s 187us/step - loss: 0.0409 - acc: 0.9854\n",
            "Epoch 127/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0401 - acc: 0.9851\n",
            "Epoch 128/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0413 - acc: 0.9855\n",
            "Epoch 129/200\n",
            "50000/50000 [==============================] - 9s 186us/step - loss: 0.0411 - acc: 0.9859\n",
            "Epoch 130/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0421 - acc: 0.9853\n",
            "Epoch 131/200\n",
            "50000/50000 [==============================] - 9s 188us/step - loss: 0.0385 - acc: 0.9862\n",
            "Epoch 132/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0393 - acc: 0.9862\n",
            "Epoch 133/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.0419 - acc: 0.9858\n",
            "Epoch 134/200\n",
            "50000/50000 [==============================] - 9s 189us/step - loss: 0.0397 - acc: 0.9858\n",
            "Epoch 135/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.0385 - acc: 0.9865\n",
            "Epoch 136/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.0407 - acc: 0.9858\n",
            "Epoch 137/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.0401 - acc: 0.9862\n",
            "Epoch 138/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.0417 - acc: 0.9856\n",
            "Epoch 139/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.0420 - acc: 0.9846\n",
            "Epoch 140/200\n",
            "50000/50000 [==============================] - 10s 191us/step - loss: 0.0402 - acc: 0.9859\n",
            "Epoch 141/200\n",
            "50000/50000 [==============================] - 10s 193us/step - loss: 0.0398 - acc: 0.9857\n",
            "Epoch 142/200\n",
            "50000/50000 [==============================] - 10s 195us/step - loss: 0.0376 - acc: 0.9869\n",
            "Epoch 143/200\n",
            "50000/50000 [==============================] - 10s 192us/step - loss: 0.0412 - acc: 0.9860\n",
            "Epoch 144/200\n",
            "50000/50000 [==============================] - 10s 192us/step - loss: 0.0386 - acc: 0.9862\n",
            "Epoch 145/200\n",
            "50000/50000 [==============================] - 10s 194us/step - loss: 0.0389 - acc: 0.9862\n",
            "Epoch 146/200\n",
            "50000/50000 [==============================] - 10s 192us/step - loss: 0.0367 - acc: 0.9869\n",
            "Epoch 147/200\n",
            "50000/50000 [==============================] - 10s 194us/step - loss: 0.0380 - acc: 0.9869\n",
            "Epoch 148/200\n",
            "50000/50000 [==============================] - 10s 194us/step - loss: 0.0372 - acc: 0.9867\n",
            "Epoch 149/200\n",
            "50000/50000 [==============================] - 10s 194us/step - loss: 0.0384 - acc: 0.9864\n",
            "Epoch 150/200\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.0376 - acc: 0.9869\n",
            "Epoch 151/200\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.0394 - acc: 0.9864\n",
            "Epoch 152/200\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.0352 - acc: 0.9879\n",
            "Epoch 153/200\n",
            "50000/50000 [==============================] - 10s 195us/step - loss: 0.0361 - acc: 0.9869\n",
            "Epoch 154/200\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.0361 - acc: 0.9872\n",
            "Epoch 155/200\n",
            "50000/50000 [==============================] - 10s 202us/step - loss: 0.0375 - acc: 0.9872\n",
            "Epoch 156/200\n",
            "50000/50000 [==============================] - 10s 195us/step - loss: 0.0358 - acc: 0.9873\n",
            "Epoch 157/200\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.0353 - acc: 0.9879\n",
            "Epoch 158/200\n",
            "50000/50000 [==============================] - 10s 200us/step - loss: 0.0357 - acc: 0.9873\n",
            "Epoch 159/200\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.0327 - acc: 0.9878\n",
            "Epoch 160/200\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.0361 - acc: 0.9868\n",
            "Epoch 161/200\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.0361 - acc: 0.9873\n",
            "Epoch 162/200\n",
            "50000/50000 [==============================] - 10s 196us/step - loss: 0.0366 - acc: 0.9872\n",
            "Epoch 163/200\n",
            "50000/50000 [==============================] - 10s 197us/step - loss: 0.0385 - acc: 0.9866\n",
            "Epoch 164/200\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 0.0354 - acc: 0.9875\n",
            "Epoch 165/200\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 0.0358 - acc: 0.9875\n",
            "Epoch 166/200\n",
            "50000/50000 [==============================] - 10s 198us/step - loss: 0.0339 - acc: 0.9879\n",
            "Epoch 167/200\n",
            "50000/50000 [==============================] - 10s 199us/step - loss: 0.0336 - acc: 0.9882\n",
            "Epoch 168/200\n",
            "50000/50000 [==============================] - 10s 199us/step - loss: 0.0362 - acc: 0.9876\n",
            "Epoch 169/200\n",
            "50000/50000 [==============================] - 10s 193us/step - loss: 0.0366 - acc: 0.9878\n",
            "10000/10000 [==============================] - 1s 127us/step\n",
            "acc: [1.6743823618888856, 0.7676]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPpN-EUJ3oM7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "908cb7b1-6aa7-4927-dcd9-245487442fcb"
      },
      "source": [
        "print(\"acc:\", model.evaluate(X_test,Y_test)[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 2s 154us/step\n",
            "acc: 0.7393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoHcSqpUDlTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf11df9c-c19f-4736-d461-6a58ae0bf0b4"
      },
      "source": [
        "def build_network_cnn(keep_prob=0.1, optimizer='adam', conv1 = 20, conv2=30, conv3=40):\n",
        "    \n",
        "    inputs = Input(shape=(32,32,3), name='input')\n",
        "    \n",
        "    x = Conv2D(conv1,(3,3),padding=\"same\",activation=\"relu\", input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNERLS))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(conv1, (3,3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(keep_prob)(x)\n",
        "    \n",
        "    x = Conv2D(conv2,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(conv2, (3,3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(keep_prob)(x)\n",
        "    \n",
        "    \n",
        "    x = Conv2D(conv3,(3,3),padding=\"same\",activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(conv3, (3,3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=2)(x)\n",
        "    x = Dropout(keep_prob)(x)\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    x = Flatten()(x)\n",
        "    prediction = Dense(10, activation='softmax', name='output')(x)\n",
        "    \n",
        "    model = Model(inputs=inputs, outputs=prediction)\n",
        " \n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',  \n",
        "                optimizer=optimizer,\n",
        "                metrics=['accuracy'])\n",
        "  \n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# score : {'model__optimizer': 'adadelta', 'model__keep_prob': 0.2, 'model__epochs': 50, 'model__conv3': 40, 'model__conv2': 70, 'model__conv1': 60, 'model__batch_size': 30}\n",
        "early = EarlyStopping(monitor=\"loss\", patience=10, mode=\"auto\")\n",
        "model2 = build_network_cnn(keep_prob=0.2, optimizer='adadelta', conv1 = 60, conv2=70,conv3=40)\n",
        "model2.fit(X_train,Y_train,batch_size=50, epochs=200, callbacks=[early])\n",
        "\n",
        "print(\"acc:\", model2.evaluate(X_test,Y_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "50000/50000 [==============================] - 18s 363us/step - loss: 1.4950 - acc: 0.4725\n",
            "Epoch 2/200\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.9588 - acc: 0.6610\n",
            "Epoch 3/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.7831 - acc: 0.7233\n",
            "Epoch 4/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.6885 - acc: 0.7594\n",
            "Epoch 5/200\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.6264 - acc: 0.7809\n",
            "Epoch 6/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.5751 - acc: 0.7989\n",
            "Epoch 7/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.5400 - acc: 0.8123\n",
            "Epoch 8/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.5087 - acc: 0.8247\n",
            "Epoch 9/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.4807 - acc: 0.8338\n",
            "Epoch 10/200\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.4526 - acc: 0.8428\n",
            "Epoch 11/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.4343 - acc: 0.8488\n",
            "Epoch 12/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.4136 - acc: 0.8562\n",
            "Epoch 13/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.3981 - acc: 0.8610\n",
            "Epoch 14/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.3859 - acc: 0.8653\n",
            "Epoch 15/200\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.3688 - acc: 0.8704\n",
            "Epoch 16/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.3600 - acc: 0.8726\n",
            "Epoch 17/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.3478 - acc: 0.8769\n",
            "Epoch 18/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.3333 - acc: 0.8820\n",
            "Epoch 19/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.3254 - acc: 0.8853\n",
            "Epoch 20/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.3153 - acc: 0.8888\n",
            "Epoch 21/200\n",
            "50000/50000 [==============================] - 15s 309us/step - loss: 0.3110 - acc: 0.8894\n",
            "Epoch 22/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.3014 - acc: 0.8925\n",
            "Epoch 23/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.2937 - acc: 0.8955\n",
            "Epoch 24/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.2885 - acc: 0.8977\n",
            "Epoch 25/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.2786 - acc: 0.9007\n",
            "Epoch 26/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.2709 - acc: 0.9036\n",
            "Epoch 27/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.2713 - acc: 0.9042\n",
            "Epoch 28/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.2586 - acc: 0.9088\n",
            "Epoch 29/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.2545 - acc: 0.9097\n",
            "Epoch 30/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.2533 - acc: 0.9103\n",
            "Epoch 31/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.2472 - acc: 0.9126\n",
            "Epoch 32/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.2452 - acc: 0.9130\n",
            "Epoch 33/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2365 - acc: 0.9159\n",
            "Epoch 34/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2317 - acc: 0.9179\n",
            "Epoch 35/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.2284 - acc: 0.9173\n",
            "Epoch 36/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2231 - acc: 0.9214\n",
            "Epoch 37/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2233 - acc: 0.9211\n",
            "Epoch 38/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2165 - acc: 0.9227\n",
            "Epoch 39/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2150 - acc: 0.9229\n",
            "Epoch 40/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2110 - acc: 0.9255\n",
            "Epoch 41/200\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.2075 - acc: 0.9262\n",
            "Epoch 42/200\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.2044 - acc: 0.9267\n",
            "Epoch 43/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.2071 - acc: 0.9272\n",
            "Epoch 44/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2119 - acc: 0.9249\n",
            "Epoch 45/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.2000 - acc: 0.9289\n",
            "Epoch 46/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1995 - acc: 0.9284\n",
            "Epoch 47/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1975 - acc: 0.9293\n",
            "Epoch 48/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1885 - acc: 0.9319\n",
            "Epoch 49/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1935 - acc: 0.9323\n",
            "Epoch 50/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1885 - acc: 0.9318\n",
            "Epoch 51/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1932 - acc: 0.9299\n",
            "Epoch 52/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1825 - acc: 0.9344\n",
            "Epoch 53/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1767 - acc: 0.9371\n",
            "Epoch 54/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1772 - acc: 0.9375\n",
            "Epoch 55/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.1742 - acc: 0.9388\n",
            "Epoch 56/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1766 - acc: 0.9371\n",
            "Epoch 57/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1700 - acc: 0.9388\n",
            "Epoch 58/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1695 - acc: 0.9398\n",
            "Epoch 59/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1691 - acc: 0.9383\n",
            "Epoch 60/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1694 - acc: 0.9388\n",
            "Epoch 61/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1657 - acc: 0.9405\n",
            "Epoch 62/200\n",
            "50000/50000 [==============================] - 15s 308us/step - loss: 0.1625 - acc: 0.9420\n",
            "Epoch 63/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1642 - acc: 0.9413\n",
            "Epoch 64/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1563 - acc: 0.9443\n",
            "Epoch 65/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1604 - acc: 0.9422\n",
            "Epoch 66/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1560 - acc: 0.9434\n",
            "Epoch 67/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1520 - acc: 0.9455\n",
            "Epoch 68/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1560 - acc: 0.9442\n",
            "Epoch 69/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1529 - acc: 0.9452\n",
            "Epoch 70/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1547 - acc: 0.9446\n",
            "Epoch 71/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1542 - acc: 0.9444\n",
            "Epoch 72/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1507 - acc: 0.9469\n",
            "Epoch 73/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1485 - acc: 0.9460\n",
            "Epoch 74/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1461 - acc: 0.9475\n",
            "Epoch 75/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1499 - acc: 0.9476\n",
            "Epoch 76/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1432 - acc: 0.9502\n",
            "Epoch 77/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1467 - acc: 0.9471\n",
            "Epoch 78/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1448 - acc: 0.9483\n",
            "Epoch 79/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1402 - acc: 0.9496\n",
            "Epoch 80/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1444 - acc: 0.9479\n",
            "Epoch 81/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1419 - acc: 0.9487\n",
            "Epoch 82/200\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.1395 - acc: 0.9503\n",
            "Epoch 83/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1362 - acc: 0.9509\n",
            "Epoch 84/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1351 - acc: 0.9511\n",
            "Epoch 85/200\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.1378 - acc: 0.9492\n",
            "Epoch 86/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1416 - acc: 0.9489\n",
            "Epoch 87/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1375 - acc: 0.9508\n",
            "Epoch 88/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1344 - acc: 0.9523\n",
            "Epoch 89/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1307 - acc: 0.9530\n",
            "Epoch 90/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1333 - acc: 0.9520\n",
            "Epoch 91/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1298 - acc: 0.9532\n",
            "Epoch 92/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1294 - acc: 0.9549\n",
            "Epoch 93/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1287 - acc: 0.9552\n",
            "Epoch 94/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1289 - acc: 0.9538\n",
            "Epoch 95/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1269 - acc: 0.9551\n",
            "Epoch 96/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1256 - acc: 0.9549\n",
            "Epoch 97/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1260 - acc: 0.9546\n",
            "Epoch 98/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1275 - acc: 0.9544\n",
            "Epoch 99/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1242 - acc: 0.9556\n",
            "Epoch 100/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1278 - acc: 0.9544\n",
            "Epoch 101/200\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.1210 - acc: 0.9557\n",
            "Epoch 102/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1241 - acc: 0.9548\n",
            "Epoch 103/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.1217 - acc: 0.9573\n",
            "Epoch 104/200\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.1222 - acc: 0.9568\n",
            "Epoch 105/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1202 - acc: 0.9571\n",
            "Epoch 106/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1176 - acc: 0.9571\n",
            "Epoch 107/200\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.1200 - acc: 0.9568\n",
            "Epoch 108/200\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.1197 - acc: 0.9579\n",
            "Epoch 109/200\n",
            "50000/50000 [==============================] - 15s 301us/step - loss: 0.1205 - acc: 0.9567\n",
            "Epoch 110/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1171 - acc: 0.9580\n",
            "Epoch 111/200\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.1160 - acc: 0.9588\n",
            "Epoch 112/200\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.1163 - acc: 0.9583\n",
            "Epoch 113/200\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.1166 - acc: 0.9580\n",
            "Epoch 114/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1118 - acc: 0.9600\n",
            "Epoch 115/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1180 - acc: 0.9583\n",
            "Epoch 116/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1133 - acc: 0.9588\n",
            "Epoch 117/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1160 - acc: 0.9583\n",
            "Epoch 118/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1110 - acc: 0.9608\n",
            "Epoch 119/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1116 - acc: 0.9601\n",
            "Epoch 120/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1128 - acc: 0.9591\n",
            "Epoch 121/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1113 - acc: 0.9595\n",
            "Epoch 122/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1111 - acc: 0.9603\n",
            "Epoch 123/200\n",
            "50000/50000 [==============================] - 15s 307us/step - loss: 0.1108 - acc: 0.9603\n",
            "Epoch 124/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1127 - acc: 0.9599\n",
            "Epoch 125/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1098 - acc: 0.9614\n",
            "Epoch 126/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1109 - acc: 0.9602\n",
            "Epoch 127/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1113 - acc: 0.9605\n",
            "Epoch 128/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1108 - acc: 0.9615\n",
            "Epoch 129/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1098 - acc: 0.9618\n",
            "Epoch 130/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1106 - acc: 0.9606\n",
            "Epoch 131/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1100 - acc: 0.9609\n",
            "Epoch 132/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1046 - acc: 0.9630\n",
            "Epoch 133/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1049 - acc: 0.9608\n",
            "Epoch 134/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1045 - acc: 0.9623\n",
            "Epoch 135/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1081 - acc: 0.9609\n",
            "Epoch 136/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.1036 - acc: 0.9633\n",
            "Epoch 137/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1073 - acc: 0.9623\n",
            "Epoch 138/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1030 - acc: 0.9639\n",
            "Epoch 139/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1018 - acc: 0.9643\n",
            "Epoch 140/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.0979 - acc: 0.9646\n",
            "Epoch 141/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1011 - acc: 0.9645\n",
            "Epoch 142/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1024 - acc: 0.9639\n",
            "Epoch 143/200\n",
            "50000/50000 [==============================] - 15s 306us/step - loss: 0.1001 - acc: 0.9646\n",
            "Epoch 144/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.1014 - acc: 0.9638\n",
            "Epoch 145/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1025 - acc: 0.9641\n",
            "Epoch 146/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.0997 - acc: 0.9645\n",
            "Epoch 147/200\n",
            "50000/50000 [==============================] - 15s 305us/step - loss: 0.0957 - acc: 0.9660\n",
            "Epoch 148/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1018 - acc: 0.9632\n",
            "Epoch 149/200\n",
            "50000/50000 [==============================] - 15s 302us/step - loss: 0.0995 - acc: 0.9646\n",
            "Epoch 150/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.0973 - acc: 0.9654\n",
            "Epoch 151/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.0950 - acc: 0.9666\n",
            "Epoch 152/200\n",
            "50000/50000 [==============================] - 15s 303us/step - loss: 0.1018 - acc: 0.9644\n",
            "Epoch 153/200\n",
            "50000/50000 [==============================] - 15s 304us/step - loss: 0.1009 - acc: 0.9635\n",
            "Epoch 154/200\n",
            "26500/50000 [==============>...............] - ETA: 7s - loss: 0.0971 - acc: 0.9652"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-067319def7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mearly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_network_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adadelta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5GVSA0bN-xw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9a940704-65b7-43db-9fe8-c095b1690a14"
      },
      "source": [
        "print(\"acc:\", model2.evaluate(X_test,Y_test)[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 144us/step\n",
            "acc: 0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyy-t7T5g7Ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}