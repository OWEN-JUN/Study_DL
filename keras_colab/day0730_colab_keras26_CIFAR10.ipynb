{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day0730_colab_keras26_CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OWEN-JUN/keras_/blob/master/day0730_colab_keras26_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cM7UWteEaSDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation,Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import *\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E36-hpvlFycU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9db83041-3de7-4c4d-ff4e-f02a1c91daf6"
      },
      "source": [
        "IMG_CHANNERLS = 3\n",
        "IMG_ROWS = 32\n",
        "IMG_COLS = 32\n",
        "\n",
        "NB_EPOCH = 80\n",
        "BATCH_SIZE = 500\n",
        "\n",
        "NB_CLASSES = 10\n",
        "VERBOSE = 1\n",
        "VALIDATION_SPLIT = 0.2\n",
        "OPTIM = RMSprop()\n",
        "# OPTIM = Adadelta\n",
        "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \" train samples\")\n",
        "print(x_test.shape[1], \" test samples\")\n",
        "\n",
        "digit = x_train[88]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "\n",
        "# dim0 = x.shape[0]\n",
        "# dim1 = x.shape[1]\n",
        "# dim2 = x.shape[2]\n",
        "# dim3 = x.shape[3]\n",
        "# x_train = x_train.reshape(dim0, dim1 * dim2 * dim3)\n",
        "# x_train = x_train.reshape(dim0, dim1 , dim2 , dim3)\n",
        "\n",
        "def make_dim(x):\n",
        "  x = x.flatten()\n",
        "  x = x.reshape(x.shape[0],1)\n",
        "  return x\n",
        "def de_dim(x):\n",
        "  x = x.flatten()\n",
        "  x = x.reshape((-1,3))\n",
        "  x = x.reshape((-1,32,3))\n",
        "  x = x.reshape((-1,32,32,3))\n",
        "  return x\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
        "print(x_train.shape)\n",
        "print(x_train[0])\n",
        "\n",
        "x_train = make_dim(x_train)\n",
        "# x_train = x_train.astype(\"float32\")\n",
        "# x_test = x_test.astype(\"float32\")\n",
        "mima = MinMaxScaler()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "mima.fit(x_train)\n",
        "scaler.fit(x_train)\n",
        "x1 = mima.transform(x_train)\n",
        "x2 = scaler.transform(x_train)\n",
        "x1 = de_dim(x1)\n",
        "x2 = de_dim(x2)\n",
        "x_test = make_dim(x_test)\n",
        "x_test1 = mima.transform(x_test)\n",
        "x_test2 = scaler.transform(x_test)\n",
        "x_test1 = de_dim(x_test1)\n",
        "\n",
        "x_test2 = de_dim(x_test2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(x[0])\n",
        "# print(x2[0])\n",
        "# x_train/= 255\n",
        "# x_test/= 255"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000  train samples\n",
            "32  test samples\n",
            "(50000, 32, 32, 3)\n",
            "[[[ 59  62  63]\n",
            "  [ 43  46  45]\n",
            "  [ 50  48  43]\n",
            "  ...\n",
            "  [158 132 108]\n",
            "  [152 125 102]\n",
            "  [148 124 103]]\n",
            "\n",
            " [[ 16  20  20]\n",
            "  [  0   0   0]\n",
            "  [ 18   8   0]\n",
            "  ...\n",
            "  [123  88  55]\n",
            "  [119  83  50]\n",
            "  [122  87  57]]\n",
            "\n",
            " [[ 25  24  21]\n",
            "  [ 16   7   0]\n",
            "  [ 49  27   8]\n",
            "  ...\n",
            "  [118  84  50]\n",
            "  [120  84  50]\n",
            "  [109  73  42]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[208 170  96]\n",
            "  [201 153  34]\n",
            "  [198 161  26]\n",
            "  ...\n",
            "  [160 133  70]\n",
            "  [ 56  31   7]\n",
            "  [ 53  34  20]]\n",
            "\n",
            " [[180 139  96]\n",
            "  [173 123  42]\n",
            "  [186 144  30]\n",
            "  ...\n",
            "  [184 148  94]\n",
            "  [ 97  62  34]\n",
            "  [ 83  53  34]]\n",
            "\n",
            " [[177 144 116]\n",
            "  [168 129  94]\n",
            "  [179 142  87]\n",
            "  ...\n",
            "  [216 184 140]\n",
            "  [151 118  84]\n",
            "  [123  92  72]]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-651c8ae13d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m# x_train/= 255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/OV5l5tIE8cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYQF6qWbafS9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1801dd7-8a72-45fc-95a4-5a8513e6ac8a"
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,(3,3),padding=\"same\", input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNERLS)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,(3,3)))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(68,(3,3),padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(68,(3,3),))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=3))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Conv2D(128,(3,3),padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128,(3,3),padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=4))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(NB_CLASSES))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "tb_hist = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIM, metrics=[\"accuracy\"])\n",
        "early_stoping_callback = EarlyStopping(monitor=\"val_loss\",patience=20)\n",
        "history = model.fit(x1, y_train, batch_size=BATCH_SIZE, epochs=1, validation_split=VALIDATION_SPLIT, verbose=VERBOSE, callbacks=[early_stoping_callback, tb_hist])\n",
        "\n",
        "print(\"Testing-----\")\n",
        "score = model.evaluate(x_test1, y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
        "\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print(\"\\nTest acc:\", score[1])\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 15, 15, 68)        19652     \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 15, 15, 68)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 15, 15, 68)        272       \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 13, 13, 68)        41684     \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 13, 13, 68)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 13, 13, 68)        272       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 68)          0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4, 4, 68)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 4, 4, 128)         78464     \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1, 1, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 300,642\n",
            "Trainable params: 299,730\n",
            "Non-trainable params: 912\n",
            "_________________________________________________________________\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/1\n",
            "40000/40000 [==============================] - 6s 152us/step - loss: 2.1768 - acc: 0.3245 - val_loss: 1.5170 - val_acc: 0.4503\n",
            "Testing-----\n",
            "10000/10000 [==============================] - 1s 56us/step\n",
            "\n",
            "Test score: 1.513695478439331\n",
            "\n",
            "Test acc: 0.45139999985694884\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jQgkwZDQw-f",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKUjJSHBaipd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "ce4264d0-d0af-4e93-ed65-20acfa30b316"
      },
      "source": [
        "plt.plot(history.history[\"acc\"])\n",
        "plt.plot(history.history[\"val_acc\"])\n",
        "\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"acc\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"train\",\"test\"], loc=\"upper left\")\n",
        "plt.show()\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.plot(history.history[\"val_loss\"])\n",
        "plt.title(\"model loss\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.legend([\"loss\",\"val_loss\"], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-94993063ba87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_acc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYcE0G8qJwY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}