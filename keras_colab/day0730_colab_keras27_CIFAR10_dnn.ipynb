{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day0730_colab_keras27_CIFAR10_dnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OWEN-JUN/keras_/blob/master/day0730_colab_keras27_CIFAR10_dnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-qVXlyMr4YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation,Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import SGD, Adam, RMSprop, Adadelta\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import *\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import keras\n",
        "import keras.regularizers as regularizers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sbBR-zqsMPr",
        "colab_type": "code",
        "outputId": "cd705364-3596-43e4-f997-8268080c6401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "IMG_CHANNERLS = 3\n",
        "IMG_ROWS = 32\n",
        "IMG_COLS = 32\n",
        "\n",
        "NB_EPOCH = 80\n",
        "BATCH_SIZE = 500\n",
        "\n",
        "NB_CLASSES = 10\n",
        "VERBOSE = 1\n",
        "VALIDATION_SPLIT = 0.2\n",
        "# OPTIM = RMSprop()\n",
        "OPTIM = Adadelta()\n",
        "(x_train, y_train),(x_test, y_test) = cifar10.load_data()\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \" train samples\")\n",
        "print(x_test.shape[1], \" test samples\")\n",
        "\n",
        "digit = x_train[88]\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "\n",
        "# dim0 = x.shape[0]\n",
        "# dim1 = x.shape[1]\n",
        "# dim2 = x.shape[2]\n",
        "# dim3 = x.shape[3]\n",
        "# x_train = x_train.reshape(dim0, dim1 * dim2 * dim3)\n",
        "# x_train = x_train.reshape(dim0, dim1 , dim2 , dim3)\n",
        "\n",
        "def make_dim(x):\n",
        "  x = x.flatten()\n",
        "  x = x.reshape(x.shape[0],1)\n",
        "  return x\n",
        "def de_dim(x):\n",
        "  x = x.flatten()\n",
        "  # x = x.reshape((-1,3))\n",
        "  # x = x.reshape((-1,32,3))\n",
        "  # x = x.reshape((-1,32,32,3))\n",
        "  x = x.reshape((-1,3072))\n",
        "  x = x.reshape((-1,3072))\n",
        "  return x\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
        "print(x_train.shape)\n",
        "print(x_train[0])\n",
        "\n",
        "x_train = make_dim(x_train)\n",
        "# x_train = x_train.astype(\"float32\")\n",
        "# x_test = x_test.astype(\"float32\")\n",
        "mima = MinMaxScaler()\n",
        "scaler = StandardScaler()\n",
        "\n",
        "mima.fit(x_train)\n",
        "scaler.fit(x_train)\n",
        "x1 = mima.transform(x_train)\n",
        "x2 = scaler.transform(x_train)\n",
        "x1 = de_dim(x1)\n",
        "x2 = de_dim(x2)\n",
        "x_test = make_dim(x_test)\n",
        "x_test1 = mima.transform(x_test)\n",
        "x_test2 = scaler.transform(x_test)\n",
        "x_test1 = de_dim(x_test1)\n",
        "\n",
        "x_test2 = de_dim(x_test2)\n",
        "print(x1.shape)\n",
        "\n",
        "# print(x[0])\n",
        "# print(x2[0])\n",
        "# x_train/= 255\n",
        "# x_test/= 255"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000  train samples\n",
            "32  test samples\n",
            "(50000, 32, 32, 3)\n",
            "[[[ 59  62  63]\n",
            "  [ 43  46  45]\n",
            "  [ 50  48  43]\n",
            "  ...\n",
            "  [158 132 108]\n",
            "  [152 125 102]\n",
            "  [148 124 103]]\n",
            "\n",
            " [[ 16  20  20]\n",
            "  [  0   0   0]\n",
            "  [ 18   8   0]\n",
            "  ...\n",
            "  [123  88  55]\n",
            "  [119  83  50]\n",
            "  [122  87  57]]\n",
            "\n",
            " [[ 25  24  21]\n",
            "  [ 16   7   0]\n",
            "  [ 49  27   8]\n",
            "  ...\n",
            "  [118  84  50]\n",
            "  [120  84  50]\n",
            "  [109  73  42]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[208 170  96]\n",
            "  [201 153  34]\n",
            "  [198 161  26]\n",
            "  ...\n",
            "  [160 133  70]\n",
            "  [ 56  31   7]\n",
            "  [ 53  34  20]]\n",
            "\n",
            " [[180 139  96]\n",
            "  [173 123  42]\n",
            "  [186 144  30]\n",
            "  ...\n",
            "  [184 148  94]\n",
            "  [ 97  62  34]\n",
            "  [ 83  53  34]]\n",
            "\n",
            " [[177 144 116]\n",
            "  [168 129  94]\n",
            "  [179 142  87]\n",
            "  ...\n",
            "  [216 184 140]\n",
            "  [151 118  84]\n",
            "  [123  92  72]]]\n",
            "(50000, 3072)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/OV5l5tIE8cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1H88ljHt9y7",
        "colab_type": "code",
        "outputId": "ad552fee-9eca-4e96-97df-6ea895f94f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "network = Sequential()\n",
        "network.add(Dense(1000, activation=\"relu\", input_shape=(3072,)))\n",
        "network.add(Dense(400, activation=\"relu\", ))\n",
        "\n",
        "network.add(Dropout(0.5))\n",
        "\n",
        "network.add(Dense(500, activation=\"relu\"))\n",
        "\n",
        "\n",
        "network.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "network.add(Dense(500, activation=\"relu\",))\n",
        "network.add(Dense(350, activation=\"relu\",))\n",
        "network.add(Dropout(0.5))\n",
        "\n",
        "network.add(Dense(200, activation=\"relu\",))\n",
        "network.add(Dense(800, activation=\"relu\",))\n",
        "network.add(Dropout(0.5))\n",
        "\n",
        "network.add(Dense(800, activation=\"relu\",))\n",
        "network.add(Dense(350, activation=\"relu\",))\n",
        "network.add(Dropout(0.5))\n",
        "\n",
        "network.add(Dense(200, activation=\"relu\",))\n",
        "network.add(Dense(700, activation=\"relu\",))\n",
        "network.add(Dropout(0.5))\n",
        "\n",
        "network.add(Dense(200, activation=\"relu\",))\n",
        "network.add(Dense(350, activation=\"relu\",))\n",
        "network.add(Dropout(0.5))\n",
        "\n",
        "network.add(Dense(400, activation=\"relu\",))\n",
        "network.add(Dense(500, activation=\"relu\",))\n",
        "network.add(BatchNormalization())\n",
        "network.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "network.add(Dense(10,activation=\"softmax\"))\n",
        "network.summary()\n",
        "\n",
        "tb_hist = keras.callbacks.TensorBoard(log_dir='./graph', histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "network.compile(loss=\"categorical_crossentropy\", optimizer=OPTIM, metrics=[\"accuracy\"])\n",
        "early_stoping_callback = EarlyStopping(monitor=\"val_acc\",patience=30)\n",
        "history = network.fit(x1, y_train, batch_size=500, epochs=300, validation_split=0.35, verbose=2, callbacks=[early_stoping_callback, tb_hist])\n",
        "\n",
        "\n",
        "print(\"Testing-----\")\n",
        "score = network.evaluate(x_test1, y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
        "\n",
        "print(\"\\nTest score:\", score[0])\n",
        "print(\"\\nTest acc:\", score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_77 (Dense)             (None, 1000)              3073000   \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 400)               400400    \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 500)               200500    \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 350)               175350    \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 200)               70200     \n",
            "_________________________________________________________________\n",
            "dense_83 (Dense)             (None, 800)               160800    \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 800)               640800    \n",
            "_________________________________________________________________\n",
            "dense_85 (Dense)             (None, 350)               280350    \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 200)               70200     \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 700)               140700    \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 700)               0         \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 200)               140200    \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 350)               70350     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 350)               0         \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 400)               140400    \n",
            "_________________________________________________________________\n",
            "dense_91 (Dense)             (None, 500)               200500    \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 500)               2000      \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 10)                5010      \n",
            "=================================================================\n",
            "Total params: 6,021,260\n",
            "Trainable params: 6,020,260\n",
            "Non-trainable params: 1,000\n",
            "_________________________________________________________________\n",
            "Train on 32500 samples, validate on 17500 samples\n",
            "Epoch 1/300\n",
            " - 3s - loss: 2.2655 - acc: 0.1423 - val_loss: 2.2870 - val_acc: 0.1167\n",
            "Epoch 2/300\n",
            " - 2s - loss: 2.1302 - acc: 0.1680 - val_loss: 2.3666 - val_acc: 0.0995\n",
            "Epoch 3/300\n",
            " - 2s - loss: 2.0962 - acc: 0.1763 - val_loss: 2.1647 - val_acc: 0.1586\n",
            "Epoch 4/300\n",
            " - 2s - loss: 2.0750 - acc: 0.1791 - val_loss: 2.5478 - val_acc: 0.1073\n",
            "Epoch 5/300\n",
            " - 2s - loss: 2.0494 - acc: 0.1849 - val_loss: 2.7726 - val_acc: 0.1010\n",
            "Epoch 6/300\n",
            " - 2s - loss: 2.0305 - acc: 0.1911 - val_loss: 2.3420 - val_acc: 0.1185\n",
            "Epoch 7/300\n",
            " - 2s - loss: 2.0159 - acc: 0.1947 - val_loss: 2.0848 - val_acc: 0.1546\n",
            "Epoch 8/300\n",
            " - 2s - loss: 2.0053 - acc: 0.1974 - val_loss: 2.2066 - val_acc: 0.1375\n",
            "Epoch 9/300\n",
            " - 2s - loss: 1.9919 - acc: 0.2016 - val_loss: 2.1411 - val_acc: 0.1522\n",
            "Epoch 10/300\n",
            " - 2s - loss: 1.9850 - acc: 0.2098 - val_loss: 1.9742 - val_acc: 0.2163\n",
            "Epoch 11/300\n",
            " - 2s - loss: 1.9710 - acc: 0.2122 - val_loss: 2.3684 - val_acc: 0.1200\n",
            "Epoch 12/300\n",
            " - 2s - loss: 1.9616 - acc: 0.2202 - val_loss: 2.0760 - val_acc: 0.1854\n",
            "Epoch 13/300\n",
            " - 2s - loss: 1.9542 - acc: 0.2262 - val_loss: 2.3629 - val_acc: 0.1297\n",
            "Epoch 14/300\n",
            " - 2s - loss: 1.9418 - acc: 0.2314 - val_loss: 2.8211 - val_acc: 0.1150\n",
            "Epoch 15/300\n",
            " - 2s - loss: 1.9314 - acc: 0.2335 - val_loss: 2.1110 - val_acc: 0.1623\n",
            "Epoch 16/300\n",
            " - 2s - loss: 1.9233 - acc: 0.2392 - val_loss: 2.6228 - val_acc: 0.1113\n",
            "Epoch 17/300\n",
            " - 2s - loss: 1.9181 - acc: 0.2426 - val_loss: 2.1684 - val_acc: 0.1509\n",
            "Epoch 18/300\n",
            " - 2s - loss: 1.9070 - acc: 0.2467 - val_loss: 2.0339 - val_acc: 0.1907\n",
            "Epoch 19/300\n",
            " - 2s - loss: 1.9049 - acc: 0.2446 - val_loss: 2.4867 - val_acc: 0.1132\n",
            "Epoch 20/300\n",
            " - 2s - loss: 1.9003 - acc: 0.2507 - val_loss: 2.0712 - val_acc: 0.1877\n",
            "Epoch 21/300\n",
            " - 2s - loss: 1.8912 - acc: 0.2509 - val_loss: 2.0426 - val_acc: 0.1967\n",
            "Epoch 22/300\n",
            " - 2s - loss: 1.8868 - acc: 0.2505 - val_loss: 2.3606 - val_acc: 0.1349\n",
            "Epoch 23/300\n",
            " - 2s - loss: 1.8821 - acc: 0.2566 - val_loss: 2.3514 - val_acc: 0.1280\n",
            "Epoch 24/300\n",
            " - 2s - loss: 1.8811 - acc: 0.2601 - val_loss: 2.0627 - val_acc: 0.1967\n",
            "Epoch 25/300\n",
            " - 2s - loss: 1.8756 - acc: 0.2616 - val_loss: 2.4064 - val_acc: 0.1122\n",
            "Epoch 26/300\n",
            " - 2s - loss: 1.8622 - acc: 0.2647 - val_loss: 2.9102 - val_acc: 0.1019\n",
            "Epoch 27/300\n",
            " - 2s - loss: 1.8579 - acc: 0.2626 - val_loss: 2.2356 - val_acc: 0.1579\n",
            "Epoch 28/300\n",
            " - 2s - loss: 1.8569 - acc: 0.2639 - val_loss: 2.2616 - val_acc: 0.1289\n",
            "Epoch 29/300\n",
            " - 2s - loss: 1.8399 - acc: 0.2762 - val_loss: 2.3119 - val_acc: 0.1389\n",
            "Epoch 30/300\n",
            " - 2s - loss: 1.8476 - acc: 0.2696 - val_loss: 2.2141 - val_acc: 0.1603\n",
            "Epoch 31/300\n",
            " - 2s - loss: 1.8430 - acc: 0.2779 - val_loss: 2.5095 - val_acc: 0.1207\n",
            "Epoch 32/300\n",
            " - 2s - loss: 1.8403 - acc: 0.2748 - val_loss: 2.1205 - val_acc: 0.1629\n",
            "Epoch 33/300\n",
            " - 2s - loss: 1.8315 - acc: 0.2814 - val_loss: 2.4424 - val_acc: 0.1285\n",
            "Epoch 34/300\n",
            " - 2s - loss: 1.8283 - acc: 0.2809 - val_loss: 2.3120 - val_acc: 0.1431\n",
            "Epoch 35/300\n",
            " - 2s - loss: 1.8183 - acc: 0.2880 - val_loss: 2.2652 - val_acc: 0.1295\n",
            "Epoch 36/300\n",
            " - 2s - loss: 1.8168 - acc: 0.2856 - val_loss: 2.3595 - val_acc: 0.1336\n",
            "Epoch 37/300\n",
            " - 2s - loss: 1.8113 - acc: 0.2885 - val_loss: 2.3149 - val_acc: 0.1462\n",
            "Epoch 38/300\n",
            " - 2s - loss: 1.8062 - acc: 0.2882 - val_loss: 2.2692 - val_acc: 0.1341\n",
            "Epoch 39/300\n",
            " - 2s - loss: 1.7949 - acc: 0.2969 - val_loss: 2.4527 - val_acc: 0.1238\n",
            "Epoch 40/300\n",
            " - 2s - loss: 1.8007 - acc: 0.2941 - val_loss: 2.0421 - val_acc: 0.1790\n",
            "Testing-----\n",
            "10000/10000 [==============================] - 0s 20us/step\n",
            "\n",
            "Test score: 2.032234954833984\n",
            "\n",
            "Test acc: 0.17950000017881393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpBGZZQNu0Z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}